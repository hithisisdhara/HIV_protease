{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "from utilities import *\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inhval(*args):\n",
    "    for val in args: \n",
    "        if val == 'NA':\n",
    "            yield 0\n",
    "        else:\n",
    "            yield float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "readfilename = 'PI_DataSet_6_19_all.txt'\n",
    "r = open(readfilename)\n",
    "header = process_line(next(r))\n",
    "inh_start = header.index('FPV') \n",
    "inh_end = header.index('DRV')+1\n",
    "vec_start = header.index('count_vec_start')\n",
    "vec_end = len(header)\n",
    "vals = []\n",
    "for line in r:\n",
    "    if line!= '\\n':\n",
    "        line = process_line(line)\n",
    "        token = list(process_inhval(*line[inh_start:inh_end])) + [int(x) for x in line[vec_start:vec_end]]\n",
    "        vals.append(token)\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.array(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_inh = {v:i for i,v in enumerate(header[inh_start:inh_end])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_inhs(data, ind_dict, *args):\n",
    "    vec_length = 210\n",
    "    names = sorted([(ind_dict[name],name) for i,name in enumerate(args)])\n",
    "    inds = list(map(lambda x:x[0], names))\n",
    "    names = list(map (lambda x:x[1], names))\n",
    "    tmp = np.hstack((data[:,inds],data[:,8:]))\n",
    "    df = pd.DataFrame(tmp, columns = ['c'+str(i) for i in range(len(tmp[0]))])\n",
    "    query_string = ' & '.join(['c'+str(i)+\">0\" for i in range(len(inds))])\n",
    "    df = df.query(query_string)\n",
    "    for i,name in enumerate(names):\n",
    "        df[names[i]] = np.where(df['c'+str(i)] > 3.0 , '1', '0')\n",
    "    df['target'] = df[names].apply(lambda x:int(''.join(x),2),axis = 1)\n",
    "    return df.iloc[:,len(names):(-len(names)-1)].values,df['target'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dshah8/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/dshah8/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "X,y = filter_inhs(vals,ind_inh,'DRV','TPV','IDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = X.max()\n",
    "X = X/max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136593, 210), (136593, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AdaBoostClassifier( DecisionTreeClassifier(max_depth=2), n_estimators=400,learning_rate=1.5,algorithm=\"SAMME\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t0 = time.time()\n",
    "scores = cross_val_score(model, X_train, y_train, cv=3)\n",
    "print(\"cross val accuracy:\", scores, \"time:\",time.time()-t0)\n",
    "print(\"average cross val accuracy:\",np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dshah8/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9857903029222034 time: 109.30507349967957\n",
      "(0.9855849590015399, 0.9857903029222034, 0.9849079486918845, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dshah8/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "model = AdaBoostClassifier( DecisionTreeClassifier(max_depth=2), n_estimators=100,learning_rate=lr,algorithm=\"SAMME\")\n",
    "t0 = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_pred,y_test)\n",
    "print (\"accuracy:\", acc,\"time:\",time.time()-t0)\n",
    "print(precision_recall_fscore_support(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
